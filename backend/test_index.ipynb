{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alirio/.cache/pypoetry/virtualenvs/app-IKRNqCx6-py3.12/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone()\n",
    "index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=index,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_df = pd.read_csv(\"qa_current.csv\")\n",
    "qa_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.engine import get_chat_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model_name = \"text-embedding-3-large\"\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=embed_model_name,\n",
    "    embed_batch_size=100,\n",
    "    max_retries=25,\n",
    "    timeout=180,\n",
    "    reuse_client=True,\n",
    "    dimensions=3072,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "max_tokens = os.getenv(\"LLM_MAX_TOKENS\")\n",
    "\n",
    "Settings.llm = OpenAI(\n",
    "    model= 'gpt-4o-mini',\n",
    "    temperature= float(0),\n",
    "    max_tokens= int(max_tokens) if max_tokens is not None else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = ''\n",
    "# chat_engine = get_chat_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = await chat_engine.achat(\"Can a friend of the church become a mentor?\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_tools import evaluate_response\n",
    "\n",
    "messages = \"\"\n",
    "chat_engine = get_chat_engine()\n",
    "new_data = []\n",
    "for index, row in qa_df.iterrows():\n",
    "    question = row[\"Question\"]\n",
    "    ideal_answer = row[\"Ideal Answer\"]\n",
    "    chat_engine.reset()\n",
    "    response = await chat_engine.achat(question)\n",
    "    retrieved = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"node_id: {idx+1}\\n{node.metadata('url')}\\n{node.text}\"\n",
    "            for idx, node in enumerate(response.source_nodes)\n",
    "        ]\n",
    "    )\n",
    "    ia_evaluation = evaluate_response(\n",
    "        question=question,\n",
    "        ideal=ideal_answer,\n",
    "        generated=response.response,\n",
    "        nodes=retrieved,\n",
    "    )\n",
    "    ia_score, ia_explanation = ia_evaluation.split(\" - \")\n",
    "    # get only the number inside ()\n",
    "    ia_score = ia_score.split(\"(\")[1].split(\")\")[0]\n",
    "\n",
    "    updated_row = row.to_dict()\n",
    "    updated_row.update(\n",
    "        {\n",
    "            \"Question\": question,\n",
    "            \"Ideal Answer\": ideal_answer,\n",
    "            \"Query Engine Answer\": response.response,\n",
    "            \"Retrieved Content\": retrieved,\n",
    "            \"ia_score\": ia_score,\n",
    "            \"ia_explanation\": ia_explanation,\n",
    "        }\n",
    "    )\n",
    "    new_data.append(updated_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(new_data)\n",
    "result_df.head()\n",
    "result_df = result_df.dropna(subset=[\"Ideal Answer\"])\n",
    "result_df.to_csv(\"chatbot_answer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-IKRNqCx6-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
